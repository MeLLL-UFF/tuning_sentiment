{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1595009919128,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "UsamTZP99FUW"
   },
   "outputs": [],
   "source": [
    "def deParaDatasetName(textDe):\n",
    "  if textDe == 'ntua':\n",
    "    return 'ntu'\n",
    "  elif textDe == 'SemEval15-Task11':\n",
    "    return 'S15'\n",
    "  elif textDe == 'iphone':\n",
    "    return 'iph'\n",
    "  elif textDe == 'Narr-KDML-2012':\n",
    "    return 'Nar'\n",
    "  elif textDe == 'VADER':\n",
    "    return 'Vad'\n",
    "  elif textDe == 'SemEval17-test':\n",
    "    return 'S17'\n",
    "  elif textDe == 'debate08':\n",
    "    return 'OMD'\n",
    "  elif textDe == 'irony':\n",
    "    return 'iro'\n",
    "  elif textDe == 'sarcasm':\n",
    "    return 'sar'\n",
    "  elif textDe == 'sentiment140':\n",
    "    return 'stm'\n",
    "  elif textDe == 'person':\n",
    "    return 'per'\n",
    "  elif textDe == 'hobbit':\n",
    "    return 'hob'\n",
    "  elif textDe == 'movie':\n",
    "    return 'mov'\n",
    "  elif textDe == 'sanders':\n",
    "    return 'san'\n",
    "  elif textDe == 'archeage':\n",
    "    return 'arc'\n",
    "  elif textDe == 'SemEval18':\n",
    "    return 'S18'\n",
    "  elif textDe == 'STS-gold':\n",
    "    return 'STS'\n",
    "  elif textDe == 'SentiStrength':\n",
    "    return 'SSt'\n",
    "  elif textDe == 'Target-dependent':\n",
    "    return 'Tar'\n",
    "  elif textDe == 'SemEval13':\n",
    "    return 'S13'\n",
    "  elif textDe == 'SemEval16':\n",
    "    return 'S16'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1595009919129,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "J4oWDmB6inaO"
   },
   "outputs": [],
   "source": [
    "def deParaEmbeddingName(textDe):\n",
    "  if textDe == 'W2V-GN':\n",
    "    return 'w2v-GN'\n",
    "  elif textDe == 'GloveWP':\n",
    "    return 'GloVe-WP'\n",
    "  elif textDe == 'FastText':\n",
    "    return 'fastText'\n",
    "  elif textDe == 'GloveTW':\n",
    "    return 'GloVe-TWT'\n",
    "  elif textDe == 'Bert: bert-base-uncased / STATIC_AVG':\n",
    "    return 'Bert-static'\n",
    "  elif textDe == 'TFIDF':\n",
    "    return 'TF-IDF'\n",
    "  elif textDe == 'W2VAraque':\n",
    "    return 'w2v-Araque'\n",
    "  elif textDe == 'W2VEdin':\n",
    "    return 'w2v-Edin'\n",
    "  elif textDe == 'Roberta: roberta-base / STATIC_AVG':\n",
    "    return 'Roberta-static'\n",
    "  elif textDe == 'Roberta: roberta-base / CONTEXT_CONCAT':\n",
    "    return 'Roberta-context'\n",
    "  elif textDe == 'Bert: bert-base-uncased / CONTEXT_CONCAT':\n",
    "    return 'Bert-context'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-6600-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Bert\\_6600k'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-25-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Roberta\\_25k'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-5-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Roberta\\_5k'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-1-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Roberta\\_1k'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-50-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Roberta\\_50k'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-250-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Roberta\\_250k'\n",
    "  elif textDe == \"Roberta: ./Seed/RoBERTa-500-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'Roberta\\_500k'\n",
    "  elif textDe == \"Roberta: ./Seed/RoBERTa-1500-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'Roberta\\_1500k'\n",
    "  elif textDe == \"Roberta: ./Seed/RoBERTa-6600-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'Roberta\\_6600k'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-25-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Bert\\_25K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-5-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Bert\\_5K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-10-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Bert\\_10K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-05-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Bert\\_05K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-50-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Bert\\_50k'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-250-12-LM / CONTEXT_CONCAT':\n",
    "    return 'Bert\\_250k'\n",
    "  elif textDe == \"Bert: ./Seed/BERT-500-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'Bert\\_500k'\n",
    "  elif textDe == \"Bert: ./Seed/BERT-1500-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'Bert\\_1500k'\n",
    "  elif textDe == \"Bert: ./Seed/BERT-6600-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'Bert\\_6600k'\n",
    "  elif textDe == \"BERTweet_base_transformers_CONTEXT\":\n",
    "    return 'Bertweet'\n",
    "  elif textDe == \"./Seed/BERTweet-50-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_50k'\n",
    "  elif textDe == \"./Seed/BERTweet-25-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_25k'\n",
    "  elif textDe == \"./Seed/BERTweet-250-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_250k'\n",
    "  elif textDe == \"./Seed/BERTweet-500-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_500k'\n",
    "  elif textDe == \"./Seed/BERTweet-1500-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_1500k'\n",
    "  elif textDe == \"./Seed/BERTweet-6600-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_6600k'\n",
    "  elif textDe == \"./Seed/BERTweet-5-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_5k'\n",
    "  elif textDe == \"./Seed/BERTweet-1-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_1k'\n",
    "  elif textDe == \"./Seed/BERTweet-05-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_05k'\n",
    "  elif textDe == \"./Seed/BERTweet-10-12-LM_CONTEXT\":\n",
    "    return 'Bertweet\\_10k'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1624,
     "status": "ok",
     "timestamp": 1595009919494,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "9qVLCGH69TdW"
   },
   "outputs": [],
   "source": [
    "def deParaClassifierName(textDe):\n",
    "  if textDe == 'MLPClassifier':\n",
    "    return 'MLP'\n",
    "  elif textDe == 'Reg_Logistica':\n",
    "    return 'LR'\n",
    "  elif textDe == 'Random_Forest':\n",
    "    return 'RF'\n",
    "  elif textDe == 'XGboost':\n",
    "    return 'Xgb'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1585,
     "status": "ok",
     "timestamp": 1595009919495,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "PhS6C9E152Xr"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "########## Contextualizado ##########\n",
    "#df_roberta = pd.read_csv(glob.glob(\"./RoBERTaXgboostLM/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "#df_bert = pd.read_csv(glob.glob(\"./BERTXgboost/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "#df_bertweet = pd.read_csv(glob.glob(\"./BERTweetXgboost/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "\n",
    "\n",
    "########## Estatico ##########\n",
    "#dfstatic = pd.read_csv(glob.glob(\"base2/Pivot_tables/Final_Result_expr1_*.csv\")[0], sep=\",\")\n",
    "#dftfidf = pd.read_csv(glob.glob(\"base2/Pivot_tables/Final_Result_tfidf_*.csv\")[0], sep=\",\")\n",
    "\n",
    "######### Within task\n",
    "#df_dataset_rob = pd.read_csv(glob.glob(\"./RoBERTXgboostFT22DTLM/Pivot_tables/Final_Result_*.csv\")[0], sep=\",\")\n",
    "#df_dataset_ber = pd.read_csv(glob.glob(\"./BERTXgboostFT22DT/Pivot_tables/Final_Result_*.csv\")[0], sep=\",\")\n",
    "#df_bt_dataset = pd.read_csv(glob.glob(\"./BERTweetXgboostFT22DT/Pivot_tables/Final_Result_*.csv\")[0], sep=\",\")\n",
    "\n",
    "############# FT RoBERTa ##############\n",
    "tag=''\n",
    "df_edin_bt_05 = pd.read_csv(glob.glob(\"./Edin/BERTweet-05-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_1 = pd.read_csv(glob.glob(\"./Edin/BERTweet-1-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_5 = pd.read_csv(glob.glob(\"./Edin/BERTweet-5-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_10 = pd.read_csv(glob.glob(\"./Edin/BERTweet-10-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_25 = pd.read_csv(glob.glob(\"./Edin/BERTweet-25-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_50 = pd.read_csv(glob.glob(\"./Edin/BERTweet-50-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_250 = pd.read_csv(glob.glob(\"./Edin/BERTweet-250-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_500 = pd.read_csv(glob.glob(\"./Edin/BERTweet-500-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bt_1500 = pd.read_csv(glob.glob(\"./Edin/BERTweet-1500-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bt_6600 = pd.read_csv(glob.glob(\"./Edin/BERTweet-6600-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "\n",
    "df_edin_bert_05 = pd.read_csv(glob.glob(\"./Edin/BERT-05-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bert_1 = pd.read_csv(glob.glob(\"./Edin/BERT-1-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bert_5 = pd.read_csv(glob.glob(\"./Edin/BERT-5-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bert_10 = pd.read_csv(glob.glob(\"./Edin/BERT-10-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bert_25 = pd.read_csv(glob.glob(\"./Edin/BERT-25-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bert_50 = pd.read_csv(glob.glob(\"./Edin/BERT-50-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bert_250 = pd.read_csv(glob.glob(\"./Edin/BERT-250-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bert_500 = pd.read_csv(glob.glob(\"./Edin/BERT-500-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_bert_1500 = pd.read_csv(glob.glob(\"./Edin/BERT-1500-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_bert_6600 = pd.read_csv(glob.glob(\"./Edin/BERT-6600-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_edin_rob_05 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-05-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_rob_1 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-1-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_rob_5 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-5-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_rob_10 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-10-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_rob_25 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-25-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_rob_50 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-50-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_rob_250 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-250-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_rob_500 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-500-LM/Final\"+str(tag)+\"*.csv\")[0],sep=\",\")\n",
    "df_edin_rob_1500 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-1500-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_edin_rob_6600 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-6600-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1595009919500,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "NCf2vK6MNjkR"
   },
   "outputs": [],
   "source": [
    "frames = [df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50, df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,\n",
    "         df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,\n",
    "         df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1595009919501,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "IwrQ3coXNuIe"
   },
   "outputs": [],
   "source": [
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1595009919502,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "SkBoFHgNwndl"
   },
   "outputs": [],
   "source": [
    "result[[\"accuracy\", \"f1_macro\"]] = result[[\"accuracy\", \"f1_macro\"]].apply(pd.to_numeric).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1595009919504,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "05WFV64O2zJN"
   },
   "outputs": [],
   "source": [
    "result[\"Data_Set\"] = result[\"Data_Set\"].apply(deParaDatasetName)\n",
    "result[\"Embedding\"] = result[\"Embedding\"].apply(deParaEmbeddingName)\n",
    "result[\"Classifier_Model\"] = result[\"Classifier_Model\"].apply(deParaClassifierName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1595009919507,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "1Idi3E1ehTaV",
    "outputId": "622eaffa-be5a-41f1-aee2-ebdd40a36ff8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Data_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>85.37</td>\n",
       "      <td>83.76</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet\\_50k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>86.45</td>\n",
       "      <td>82.95</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bert\\_50k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81.92</td>\n",
       "      <td>75.09</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Roberta\\_25k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.99</td>\n",
       "      <td>73.99</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Roberta\\_25k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.41</td>\n",
       "      <td>64.37</td>\n",
       "      <td>RF</td>\n",
       "      <td>Roberta\\_25k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.89</td>\n",
       "      <td>78.21</td>\n",
       "      <td>LR</td>\n",
       "      <td>Roberta\\_25k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>84.31</td>\n",
       "      <td>71.37</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bertweet\\_6600k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>87.15</td>\n",
       "      <td>80.50</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bertweet\\_6600k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>86.54</td>\n",
       "      <td>80.66</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet\\_6600k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>82.61</td>\n",
       "      <td>62.44</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet\\_6600k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>86.17</td>\n",
       "      <td>80.90</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet\\_6600k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>86.46</td>\n",
       "      <td>84.11</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bert\\_50k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.57</td>\n",
       "      <td>77.45</td>\n",
       "      <td>LR</td>\n",
       "      <td>Roberta\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>82.95</td>\n",
       "      <td>77.99</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Roberta\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>84.01</td>\n",
       "      <td>76.97</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Roberta\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>83.00</td>\n",
       "      <td>80.06</td>\n",
       "      <td>LR</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>80.21</td>\n",
       "      <td>68.07</td>\n",
       "      <td>RF</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>81.01</td>\n",
       "      <td>78.50</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>83.16</td>\n",
       "      <td>79.41</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>84.45</td>\n",
       "      <td>79.46</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>84.46</td>\n",
       "      <td>74.34</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Roberta\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>86.13</td>\n",
       "      <td>75.49</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bertweet\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>87.72</td>\n",
       "      <td>82.16</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bertweet\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>81.57</td>\n",
       "      <td>62.84</td>\n",
       "      <td>RF</td>\n",
       "      <td>Roberta\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>87.22</td>\n",
       "      <td>81.85</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet\\_250k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>86.53</td>\n",
       "      <td>84.73</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet\\_05k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>85.08</td>\n",
       "      <td>83.39</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet\\_05k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>85.93</td>\n",
       "      <td>83.46</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>80.71</td>\n",
       "      <td>69.35</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>86.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>HCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>73.12</td>\n",
       "      <td>67.87</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>83.55</td>\n",
       "      <td>81.82</td>\n",
       "      <td>LR</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>81.73</td>\n",
       "      <td>79.98</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet\\_50k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>85.65</td>\n",
       "      <td>85.09</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet\\_50k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90.43</td>\n",
       "      <td>89.89</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet\\_500k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>85.28</td>\n",
       "      <td>82.93</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet\\_500k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>86.72</td>\n",
       "      <td>79.02</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.24</td>\n",
       "      <td>84.55</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bert: ./Seed/BERT-1-12-LM / CONTEXT_CONCAT</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>80.74</td>\n",
       "      <td>72.60</td>\n",
       "      <td>RF</td>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>92.06</td>\n",
       "      <td>89.27</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet\\_5k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>82.04</td>\n",
       "      <td>67.31</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bert\\_05K</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>90.22</td>\n",
       "      <td>86.95</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>85.79</td>\n",
       "      <td>82.70</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet\\_1500k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>89.36</td>\n",
       "      <td>88.67</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bertweet\\_1500k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>90.82</td>\n",
       "      <td>89.82</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bertweet\\_1500k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>83.75</td>\n",
       "      <td>83.58</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bert\\_50k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>86.03</td>\n",
       "      <td>85.93</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bert\\_50k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>88.11</td>\n",
       "      <td>88.03</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Bert\\_50k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>82.78</td>\n",
       "      <td>82.59</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bert\\_50k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>89.76</td>\n",
       "      <td>85.85</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>86.17</td>\n",
       "      <td>86.09</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bert\\_50k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>90.16</td>\n",
       "      <td>86.88</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>85.54</td>\n",
       "      <td>72.77</td>\n",
       "      <td>RF</td>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85.81</td>\n",
       "      <td>85.74</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Roberta\\_5k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>89.08</td>\n",
       "      <td>89.02</td>\n",
       "      <td>MLP</td>\n",
       "      <td>Roberta\\_5k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>88.20</td>\n",
       "      <td>88.14</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Roberta\\_5k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>87.62</td>\n",
       "      <td>87.53</td>\n",
       "      <td>RF</td>\n",
       "      <td>Roberta\\_5k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90.74</td>\n",
       "      <td>90.69</td>\n",
       "      <td>LR</td>\n",
       "      <td>Roberta\\_5k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>85.58</td>\n",
       "      <td>81.65</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bert\\_05K</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>87.90</td>\n",
       "      <td>86.24</td>\n",
       "      <td>Xgb</td>\n",
       "      <td>Bertweet\\_1500k</td>\n",
       "      <td>stm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3300 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  f1_macro Classifier_Model  \\\n",
       "92      85.37     83.76              SVM   \n",
       "59      86.45     82.95              Xgb   \n",
       "9       81.92     75.09              Xgb   \n",
       "7       76.99     73.99              SVM   \n",
       "6       78.41     64.37               RF   \n",
       "5       81.89     78.21               LR   \n",
       "34      84.31     71.37              Xgb   \n",
       "33      87.15     80.50              MLP   \n",
       "32      86.54     80.66              SVM   \n",
       "31      82.61     62.44               RF   \n",
       "30      86.17     80.90               LR   \n",
       "58      86.46     84.11              MLP   \n",
       "95      83.57     77.45               LR   \n",
       "97      82.95     77.99              SVM   \n",
       "98      84.01     76.97              MLP   \n",
       "95      83.00     80.06               LR   \n",
       "96      80.21     68.07               RF   \n",
       "97      81.01     78.50              SVM   \n",
       "98      83.16     79.41              MLP   \n",
       "99      84.45     79.46              Xgb   \n",
       "99      84.46     74.34              Xgb   \n",
       "109     86.13     75.49              Xgb   \n",
       "108     87.72     82.16              MLP   \n",
       "96      81.57     62.84               RF   \n",
       "107     87.22     81.85              SVM   \n",
       "25      86.53     84.73               LR   \n",
       "27      85.08     83.39              SVM   \n",
       "42      85.93     83.46              SVM   \n",
       "41      80.71     69.35               RF   \n",
       "40      86.96     84.33               LR   \n",
       "..        ...       ...              ...   \n",
       "92      73.12     67.87              SVM   \n",
       "90      83.55     81.82               LR   \n",
       "31      81.73     79.98               RF   \n",
       "30      85.65     85.09               LR   \n",
       "10      90.43     89.89               LR   \n",
       "11      85.28     82.93               RF   \n",
       "34      86.72     79.02              Xgb   \n",
       "0       85.24     84.55               LR   \n",
       "91      80.74     72.60               RF   \n",
       "60      92.06     89.27               LR   \n",
       "76      82.04     67.31               RF   \n",
       "32      90.22     86.95              SVM   \n",
       "96      85.79     82.70               RF   \n",
       "97      89.36     88.67              SVM   \n",
       "98      90.82     89.82              MLP   \n",
       "79      83.75     83.58              Xgb   \n",
       "78      86.03     85.93              MLP   \n",
       "77      88.11     88.03              SVM   \n",
       "76      82.78     82.59               RF   \n",
       "33      89.76     85.85              MLP   \n",
       "75      86.17     86.09               LR   \n",
       "30      90.16     86.88               LR   \n",
       "31      85.54     72.77               RF   \n",
       "19      85.81     85.74              Xgb   \n",
       "18      89.08     89.02              MLP   \n",
       "17      88.20     88.14              SVM   \n",
       "16      87.62     87.53               RF   \n",
       "15      90.74     90.69               LR   \n",
       "75      85.58     81.65               LR   \n",
       "99      87.90     86.24              Xgb   \n",
       "\n",
       "                                      Embedding Data_Set  \n",
       "92                                Bertweet\\_50k      HCR  \n",
       "59                                    Bert\\_50k      HCR  \n",
       "9                                  Roberta\\_25k      HCR  \n",
       "7                                  Roberta\\_25k      HCR  \n",
       "6                                  Roberta\\_25k      HCR  \n",
       "5                                  Roberta\\_25k      HCR  \n",
       "34                              Bertweet\\_6600k      HCR  \n",
       "33                              Bertweet\\_6600k      HCR  \n",
       "32                              Bertweet\\_6600k      HCR  \n",
       "31                              Bertweet\\_6600k      HCR  \n",
       "30                              Bertweet\\_6600k      HCR  \n",
       "58                                    Bert\\_50k      HCR  \n",
       "95                                Roberta\\_250k      HCR  \n",
       "97                                Roberta\\_250k      HCR  \n",
       "98                                Roberta\\_250k      HCR  \n",
       "95                                  Roberta\\_1k      HCR  \n",
       "96                                  Roberta\\_1k      HCR  \n",
       "97                                  Roberta\\_1k      HCR  \n",
       "98                                  Roberta\\_1k      HCR  \n",
       "99                                  Roberta\\_1k      HCR  \n",
       "99                                Roberta\\_250k      HCR  \n",
       "109                              Bertweet\\_250k      HCR  \n",
       "108                              Bertweet\\_250k      HCR  \n",
       "96                                Roberta\\_250k      HCR  \n",
       "107                              Bertweet\\_250k      HCR  \n",
       "25                                Bertweet\\_05k      HCR  \n",
       "27                                Bertweet\\_05k      HCR  \n",
       "42                                Bertweet\\_10k      HCR  \n",
       "41                                Bertweet\\_10k      HCR  \n",
       "40                                Bertweet\\_10k      HCR  \n",
       "..                                          ...      ...  \n",
       "92                                  Roberta\\_1k      stm  \n",
       "90                                  Roberta\\_1k      stm  \n",
       "31                                Bertweet\\_50k      stm  \n",
       "30                                Bertweet\\_50k      stm  \n",
       "10                               Bertweet\\_500k      stm  \n",
       "11                               Bertweet\\_500k      stm  \n",
       "34                                Bertweet\\_10k      stm  \n",
       "0    Bert: ./Seed/BERT-1-12-LM / CONTEXT_CONCAT      stm  \n",
       "91                                  Roberta\\_1k      stm  \n",
       "60                                 Bertweet\\_5k      stm  \n",
       "76                                    Bert\\_05K      stm  \n",
       "32                                Bertweet\\_10k      stm  \n",
       "96                              Bertweet\\_1500k      stm  \n",
       "97                              Bertweet\\_1500k      stm  \n",
       "98                              Bertweet\\_1500k      stm  \n",
       "79                                    Bert\\_50k      stm  \n",
       "78                                    Bert\\_50k      stm  \n",
       "77                                    Bert\\_50k      stm  \n",
       "76                                    Bert\\_50k      stm  \n",
       "33                                Bertweet\\_10k      stm  \n",
       "75                                    Bert\\_50k      stm  \n",
       "30                                Bertweet\\_10k      stm  \n",
       "31                                Bertweet\\_10k      stm  \n",
       "19                                  Roberta\\_5k      stm  \n",
       "18                                  Roberta\\_5k      stm  \n",
       "17                                  Roberta\\_5k      stm  \n",
       "16                                  Roberta\\_5k      stm  \n",
       "15                                  Roberta\\_5k      stm  \n",
       "75                                    Bert\\_05K      stm  \n",
       "99                              Bertweet\\_1500k      stm  \n",
       "\n",
       "[3300 rows x 5 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values(by='Data_Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1595009919507,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "dP9oWlPFxk4X"
   },
   "outputs": [],
   "source": [
    "#result[(result['Classifier_Model'] == 'MLPClassifier') & (result['Embedding'] == 'Bert-context')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1595009919508,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "n2i9Vw-ahUnG"
   },
   "outputs": [],
   "source": [
    "result_acc = result.sort_values(by=['Data_Set', 'accuracy'], ascending=False)\n",
    "result_f1 = result.sort_values(by=['Data_Set', 'f1_macro'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1288,
     "status": "ok",
     "timestamp": 1595009919509,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "Mq6A-3oomtFD"
   },
   "outputs": [],
   "source": [
    "result_acc = result_acc.drop_duplicates(subset='Data_Set', keep=\"first\")\n",
    "result_acc=result_acc.reset_index(drop=True)\n",
    "result_f1 = result_f1.drop_duplicates(subset='Data_Set', keep=\"first\")\n",
    "result_f1=result_f1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1595009919509,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "yRP2Qkz3-Wwq"
   },
   "outputs": [],
   "source": [
    "def montaTabelaLatex(df, metrica):\n",
    "  first = True\n",
    "  for ind in df.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.8ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print ('&'+str(df[metrica][ind])+'&'+str(df[\"Classifier_Model\"][ind])+'&'+str(df[\"Embedding\"][ind])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montaTabelaLatexNew(df_acc, df_f1):\n",
    "  first = True\n",
    "  for ind in df_acc.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.8ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df_acc[\"Data_Set\"][ind])+'&'+str(df_acc['accuracy'][ind])+'&'+str(df_acc[\"Classifier_Model\"][ind])+'&'+str(df_acc[\"Embedding\"][ind])+'&'+str(df_f1['f1_macro'][ind])+'&'+str(df_f1[\"Classifier_Model\"][ind])+'&'+str(df_f1[\"Embedding\"][ind])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1595009919510,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "QgBvWDTI4wG8"
   },
   "outputs": [],
   "source": [
    "result_acc = result_acc.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Data_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bertweet\\_25k</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bertweet\\_50k</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bertweet\\_5k</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bertweet\\_1k</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bertweet\\_250k</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bertweet\\_500k</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bertweet\\_05k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Roberta\\_1k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Roberta\\_50k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Roberta\\_6600k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Embedding  Data_Set\n",
       "0    Bertweet\\_10k         3\n",
       "1    Bertweet\\_25k         3\n",
       "2    Bertweet\\_50k         3\n",
       "3     Bertweet\\_5k         3\n",
       "4     Bertweet\\_1k         2\n",
       "5   Bertweet\\_250k         2\n",
       "6   Bertweet\\_500k         2\n",
       "7    Bertweet\\_05k         1\n",
       "8      Roberta\\_1k         1\n",
       "9     Roberta\\_50k         1\n",
       "10  Roberta\\_6600k         1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc = result_acc[['Embedding','Data_Set']].groupby(by='Embedding').count().sort_values(by='Data_Set',ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>Data_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xgb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier_Model  Data_Set\n",
       "0              MLP         8\n",
       "1               LR         7\n",
       "2              SVM         6\n",
       "3              Xgb         1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_class = result_acc[['Classifier_Model','Data_Set']].groupby(by='Classifier_Model').count().sort_values(by='Data_Set',ascending=False).reset_index()\n",
    "best_acc_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1483,
     "status": "ok",
     "timestamp": 1595009919788,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "4-024kz-8Hz5"
   },
   "outputs": [],
   "source": [
    "result_f1 = result_f1.reindex([6,1,4,17,0,3,8,7,5,2,20,9,14,19,21,12,13,11,10,18,15,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Data_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bertweet\\_5k</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bertweet\\_25k</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bertweet\\_10k</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bertweet\\_50k</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bertweet\\_1k</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bertweet\\_05k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bertweet\\_1500k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bertweet\\_250k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Roberta\\_50k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Roberta\\_5k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Embedding  Data_Set\n",
       "0     Bertweet\\_5k         5\n",
       "1    Bertweet\\_25k         4\n",
       "2    Bertweet\\_10k         3\n",
       "3    Bertweet\\_50k         3\n",
       "4     Bertweet\\_1k         2\n",
       "5    Bertweet\\_05k         1\n",
       "6  Bertweet\\_1500k         1\n",
       "7   Bertweet\\_250k         1\n",
       "8     Roberta\\_50k         1\n",
       "9      Roberta\\_5k         1"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1 = result_f1[['Embedding','Data_Set']].groupby(by='Embedding').count().sort_values(by='Data_Set',ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summarization(acc,f1,colu):\n",
    "    acc = acc.merge(f1,how='outer',left_on=['index'],right_on=['index'])\n",
    "    print(acc)\n",
    "    for i,row in acc.iterrows():\n",
    "        print(str(row['index'])+\"&\"+str(row[str(colu)+'_x'])+\"&\"+str(row[str(colu)+'_y'])+\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              index  Embedding_x  Embedding_y\n",
      "0      Bertweet\\_5k          3.0          5.0\n",
      "1     Bertweet\\_10k          3.0          3.0\n",
      "2     Bertweet\\_25k          3.0          4.0\n",
      "3     Bertweet\\_50k          3.0          3.0\n",
      "4    Bertweet\\_500k          2.0          NaN\n",
      "5    Bertweet\\_250k          2.0          1.0\n",
      "6      Bertweet\\_1k          2.0          2.0\n",
      "7    Roberta\\_6600k          1.0          NaN\n",
      "8       Roberta\\_1k          1.0          NaN\n",
      "9      Roberta\\_50k          1.0          1.0\n",
      "10    Bertweet\\_05k          1.0          1.0\n",
      "11  Bertweet\\_1500k          NaN          1.0\n",
      "12      Roberta\\_5k          NaN          1.0\n",
      "Bertweet\\_5k&3.0&5.0\\\\\n",
      "Bertweet\\_10k&3.0&3.0\\\\\n",
      "Bertweet\\_25k&3.0&4.0\\\\\n",
      "Bertweet\\_50k&3.0&3.0\\\\\n",
      "Bertweet\\_500k&2.0&nan\\\\\n",
      "Bertweet\\_250k&2.0&1.0\\\\\n",
      "Bertweet\\_1k&2.0&2.0\\\\\n",
      "Roberta\\_6600k&1.0&nan\\\\\n",
      "Roberta\\_1k&1.0&nan\\\\\n",
      "Roberta\\_50k&1.0&1.0\\\\\n",
      "Bertweet\\_05k&1.0&1.0\\\\\n",
      "Bertweet\\_1500k&nan&1.0\\\\\n",
      "Roberta\\_5k&nan&1.0\\\\\n"
     ]
    }
   ],
   "source": [
    "acc = pd.DataFrame(result_acc['Embedding'].value_counts()).reset_index()\n",
    "f1 = pd.DataFrame(result_f1['Embedding'].value_counts()).reset_index()\n",
    "print_summarization(acc,f1,\"Embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  Classifier_Model_x  Classifier_Model_y\n",
      "0   MLP                   8                 3.0\n",
      "1    LR                   7                 9.0\n",
      "2   SVM                   6                10.0\n",
      "3   Xgb                   1                 NaN\n",
      "MLP&8&3.0\\\\\n",
      "LR&7&9.0\\\\\n",
      "SVM&6&10.0\\\\\n",
      "Xgb&1&nan\\\\\n"
     ]
    }
   ],
   "source": [
    "acc = pd.DataFrame(result_acc['Classifier_Model'].value_counts()).reset_index()\n",
    "f1 = pd.DataFrame(result_f1['Classifier_Model'].value_counts()).reset_index()\n",
    "print_summarization(acc,f1,\"Classifier_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>Data_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier_Model  Data_Set\n",
       "0              SVM        10\n",
       "1               LR         9\n",
       "2              MLP         3"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1_class = result_f1[['Classifier_Model','Data_Set']].groupby(by='Classifier_Model').count().sort_values(by='Data_Set',ascending=False).reset_index()\n",
    "best_f1_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1453,
     "status": "ok",
     "timestamp": 1595009919790,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "Bkj903_90iJl",
    "outputId": "51c69624-044c-415d-98a8-78cc3a890741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iro&89.67&MLP&Bertweet\\_50k&87.31&SVM&Bertweet\\_50k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "sar&85.84&Xgb&Roberta\\_6600k&84.48&MLP&Roberta\\_5k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "ntu&91.55&MLP&Bertweet\\_5k&91.4&MLP&Bertweet\\_5k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S15&92.67&MLP&Bertweet\\_500k&89.24&SVM&Bertweet\\_10k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "stm&93.94&LR&Bertweet\\_1k&93.75&LR&Bertweet\\_1k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "per&90.85&MLP&Bertweet\\_10k&89.68&LR&Bertweet\\_5k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "hob&91.15&LR&Bertweet\\_5k&89.81&LR&Bertweet\\_5k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "iph&90.05&MLP&Roberta\\_1k&88.65&MLP&Bertweet\\_1500k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "mov&91.69&MLP&Bertweet\\_25k&88.99&LR&Bertweet\\_25k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "san&92.58&LR&Bertweet\\_05k&92.12&LR&Bertweet\\_05k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Nar&94.06&SVM&Bertweet\\_5k&93.66&SVM&Bertweet\\_5k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "arc&93.41&LR&Bertweet\\_10k&93.26&LR&Bertweet\\_10k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S18&93.18&SVM&Bertweet\\_10k&92.76&SVM&Bertweet\\_10k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "OMD&90.99&SVM&Bertweet\\_25k&90.04&SVM&Bertweet\\_25k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "HCR&87.73&LR&Roberta\\_50k&85.65&LR&Roberta\\_50k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "STS&93.05&SVM&Bertweet\\_50k&92.75&SVM&Bertweet\\_50k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "SSt&92.71&LR&Bertweet\\_1k&92.18&LR&Bertweet\\_1k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Tar&92.02&SVM&Bertweet\\_250k&91.97&SVM&Bertweet\\_250k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "Vad&91.83&LR&Bertweet\\_250k&90.96&SVM&Bertweet\\_25k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S13&92.55&MLP&Bertweet\\_50k&91.02&LR&Bertweet\\_5k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S17&92.55&SVM&Bertweet\\_25k&92.34&SVM&Bertweet\\_25k\\\\\n",
      "\\rule{0pt}{3.8ex}\n",
      "S16&92.91&MLP&Bertweet\\_500k&90.59&SVM&Bertweet\\_50k\\\\\n"
     ]
    }
   ],
   "source": [
    "montaTabelaLatexNew(result_acc,result_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNu7AB0kwJRPr+r17jbMTv3",
   "collapsed_sections": [],
   "mount_file_id": "18YqNJ9EiloCFcgw03FIBpEvdUpPY5fCt",
   "name": "organize_result_bestoverall.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
