{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deParaClassifierName(textDe):\n",
    "  if textDe == 'MLPClassifier':\n",
    "    return 'MLP'\n",
    "  elif textDe == 'Reg_Logistica':\n",
    "    return 'LR'\n",
    "  elif textDe == 'Random_Forest':\n",
    "    return 'RF'\n",
    "  elif textDe == 'XGboost':\n",
    "    return 'Xgb'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280,
     "status": "ok",
     "timestamp": 1595009919129,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "J4oWDmB6inaO"
   },
   "outputs": [],
   "source": [
    "def deParaEmbeddingName(textDe):\n",
    "  if textDe == 'W2V-GN':\n",
    "    return 'w2v-GN'\n",
    "  elif textDe == 'GloveWP':\n",
    "    return 'GloVe-WP'\n",
    "  elif textDe == 'FastText':\n",
    "    return 'fastText'\n",
    "  elif textDe == 'GloveTW':\n",
    "    return 'GloVe-TWT'\n",
    "  elif textDe == 'Bert: bert-base-uncased / STATIC_AVG':\n",
    "    return 'BERT-static'\n",
    "  elif textDe == 'TFIDF':\n",
    "    return 'TF-IDF'\n",
    "  elif textDe == 'W2VAraque':\n",
    "    return 'w2v-Araque'\n",
    "  elif textDe == 'W2VEdin':\n",
    "    return 'w2v-Edin'\n",
    "  elif textDe == 'Roberta: roberta-base / STATIC_AVG':\n",
    "    return 'RoBERTa-static'\n",
    "\n",
    "  elif textDe == 'Roberta: roberta-base / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa'\n",
    "  elif textDe == 'Bert: bert-base-uncased / CONTEXT_CONCAT':\n",
    "    return 'BERT'\n",
    "  \n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-05-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-0.5K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-1-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-1K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-5-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-5K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-10-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-10K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-25-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-25K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-50-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-50K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-250-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-250K'\n",
    "  elif textDe == \"Roberta: ./Seed/RoBERTa-500-12-LM / CONTEXT_CONCAT\":\n",
    "    return 'RoBERTa-500K'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-1500-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-1.5M'\n",
    "  elif textDe == 'Roberta: ./Seed/RoBERTa-6600-12-LM / CONTEXT_CONCAT':\n",
    "    return 'RoBERTa-6.6M'\n",
    "  \n",
    "\n",
    "  elif textDe == 'Bert: ./Seed/BERT-05-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-0.5K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-1-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-1K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-5-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-5K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-10-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-10K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-25-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-25K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-50-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-50K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-250-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-250K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-500-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-500K'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-1500-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-1.5M'\n",
    "  elif textDe == 'Bert: ./Seed/BERT-6600-12-LM / CONTEXT_CONCAT':\n",
    "    return 'BERT-6.6M'\n",
    "\n",
    "  elif textDe == \"BERTweet_base_transformers_CONTEXT\":\n",
    "    return 'BERTweet'\n",
    "  elif textDe == \"./Seed/BERTweet-05-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-0.5K'\n",
    "  elif textDe == \"./Seed/BERTweet-1-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-1K'\n",
    "  elif textDe == \"./Seed/BERTweet-5-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-5K'\n",
    "  elif textDe == \"./Seed/BERTweet-10-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-10K'\n",
    "  elif textDe == \"./Seed/BERTweet-50-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-50K'\n",
    "  elif textDe == \"./Seed/BERTweet-25-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-25K'\n",
    "  elif textDe == \"./Seed/BERTweet-250-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-250K'\n",
    "  elif textDe == \"./Seed/BERTweet-500-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-500K'\n",
    "  elif textDe == \"./Seed/BERTweet-1500-12-LM_CONTEXT\":\n",
    "    return 'BERTweet\\_1.5M'\n",
    "  elif textDe == \"./Seed/BERTweet-6600-12-LM_CONTEXT\":\n",
    "    return 'BERTweet-6.6M'\n",
    "\n",
    "\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1624,
     "status": "ok",
     "timestamp": 1595009919494,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "9qVLCGH69TdW"
   },
   "outputs": [],
   "source": [
    "def deParaDatasetName(textDe):\n",
    "  if textDe == 'ntua':\n",
    "    return 'ntu'\n",
    "  elif textDe == 'SemEval15-Task11':\n",
    "    return 'S15'\n",
    "  elif textDe == 'iphone':\n",
    "    return 'iph'\n",
    "  elif textDe == 'Narr-KDML-2012':\n",
    "    return 'Nar'\n",
    "  elif textDe == 'VADER':\n",
    "    return 'Vad'\n",
    "  elif textDe == 'SemEval17-test':\n",
    "    return 'S17'\n",
    "  elif textDe == 'debate08':\n",
    "    return 'OMD'\n",
    "  elif textDe == 'irony':\n",
    "    return 'iro'\n",
    "  elif textDe == 'sarcasm':\n",
    "    return 'sar'\n",
    "  elif textDe == 'sentiment140':\n",
    "    return 'stm'\n",
    "  elif textDe == 'person':\n",
    "    return 'per'\n",
    "  elif textDe == 'hobbit':\n",
    "    return 'hob'\n",
    "  elif textDe == 'movie':\n",
    "    return 'mov'\n",
    "  elif textDe == 'sanders':\n",
    "    return 'san'\n",
    "  elif textDe == 'archeage':\n",
    "    return 'arc'\n",
    "  elif textDe == 'SemEval18':\n",
    "    return 'S18'\n",
    "  elif textDe == 'STS-gold':\n",
    "    return 'STS'\n",
    "  elif textDe == 'SentiStrength':\n",
    "    return 'SSt'\n",
    "  elif textDe == 'Target-dependent':\n",
    "    return 'Tar'\n",
    "  elif textDe == 'SemEval13':\n",
    "    return 'S13'\n",
    "  elif textDe == 'SemEval16':\n",
    "    return 'S16'\n",
    "  else:\n",
    "    return textDe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1595009919509,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "yRP2Qkz3-Wwq"
   },
   "outputs": [],
   "source": [
    "def montaTabelaLatex(df, metrica):\n",
    "  first = True\n",
    "  for ind in df.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.0ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df[\"Data_Set\"][ind])+'&'+str(df[metrica][ind])+'&'+str(df[\"Classifier_Model\"][ind])+'&'+str(df[\"Embedding\"][ind])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monta_tabela_latex_top_rank_sum(df_acc, df_f1):\n",
    "  first = True\n",
    "  for ind in df_acc.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.0ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df_acc[\"Embedding\"][ind])+'&'+str(df_acc[\"Classifier_Model\"][ind])+'&' \\\n",
    "           +str(round(df_acc['rank'][ind]/22,2))+'&'+str(df_f1[\"Embedding\"][ind])+'&' \\\n",
    "           +str(df_f1[\"Classifier_Model\"][ind])+'&'+str(round(df_f1['rank'][ind]/22,2))+ \\\n",
    "           '\\\\\\\\')\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monta_tabela_latex_top_rank_sum_class(df_acc, df_f1):\n",
    "  first = True\n",
    "  for ind in df_acc.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.0ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df_acc[\"Classifier_Model\"][ind])+'&' \\\n",
    "           +str(round(df_acc['rank'][ind]/1232,2))+'&' \\\n",
    "           +str(df_f1[\"Classifier_Model\"][ind])+'&'+str(round(df_f1['rank'][ind]/1232,2))+ \\\n",
    "           '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monta_tabela_latex_top_rank_sum_emb(df_acc, df_f1):\n",
    "  first = True\n",
    "  for ind in df_acc.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.0ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df_acc[\"Embedding\"][ind])+'&' \\\n",
    "           +str(round(df_acc['rank'][ind]/110,2))+'&'+str(df_f1[\"Embedding\"][ind])+'&' \\\n",
    "           +str(round(df_f1['rank'][ind]/110,2))+ \\\n",
    "           '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montaTabelaLatexNew(df_acc, df_f1):\n",
    "  first = True\n",
    "  for ind in df_acc.index:\n",
    "    if first == False:\n",
    "      print(\"\\\\rule{0pt}{3.0ex}\")\n",
    "    else:\n",
    "      first = False\n",
    "    print (str(df_acc[\"Data_Set\"][ind])+'&'+str(round(df_acc['accuracy'][ind],2))+'&'+str(df_acc[\"Classifier_Model\"][ind])+'&'+str(df_acc[\"Embedding\"][ind])+'&'+str(round(df_f1['f1_macro'][ind],2))+'&'+str(df_f1[\"Classifier_Model\"][ind])+'&'+str(df_f1[\"Embedding\"][ind])+'\\\\\\\\')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1585,
     "status": "ok",
     "timestamp": 1595009919495,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "PhS6C9E152Xr"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "########## Estatico ##########\n",
    "dfStatic = pd.read_csv(glob.glob(\"Static-STATIC-NEW-1234-LM/Pivot_tables/Final_Result_*.csv\")[0], sep=\",\")\n",
    "\n",
    "\n",
    "########## Contextualizado ##########\n",
    "df_roberta = pd.read_csv(glob.glob(\"./RoBERTa/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "df_bert = pd.read_csv(glob.glob(\"./BERT/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "df_bertweet = pd.read_csv(glob.glob(\"./BERTweet/Pivot_tables/Final_Result_*.csv\")[0],sep=\",\")\n",
    "tag=''\n",
    "\n",
    "############## FT LOO ##################\n",
    "df_LOO_bt = pd.read_csv(glob.glob(\"./LOO/BERTweet-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_LOO_bt['accuracy'] = round(df_LOO_bt['accuracy']/100,2)\n",
    "df_LOO_bt['f1_macro'] = round(df_LOO_bt['f1_macro']/100,2)\n",
    "\n",
    "df_LOO_br = pd.read_csv(glob.glob(\"./LOO/BERT-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_LOO_br['accuracy'] = round(df_LOO_br['accuracy']/100,2)\n",
    "df_LOO_br['f1_macro'] = round(df_LOO_br['f1_macro']/100,2)\n",
    "\n",
    "df_LOO_rb = pd.read_csv(glob.glob(\"./LOO/RoBERTa-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "df_LOO_rb['accuracy'] = round(df_LOO_rb['accuracy']/100,2)\n",
    "df_LOO_rb['f1_macro'] = round(df_LOO_rb['f1_macro']/100,2)\n",
    "\n",
    "\n",
    "############### FT 22DT ##############3\n",
    "\n",
    "df_22dt_rb = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/RoBERTa-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_22dt_br = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/BERT-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_22dt_bt = pd.read_csv(glob.glob(\"/Users/sergiojunior/sentiment-embeddings/scripts_artigo/22Dt/BERTweet-LM/Final_Result*.csv\")[0], sep=\",\")\n",
    "\n",
    "############## FT Indata #################\n",
    "\n",
    "df_Indata_bt = pd.read_csv(glob.glob(\"./InData/BERTweet-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_Indata_br = pd.read_csv(glob.glob(\"./InData/BERT-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "df_Indata_rb = pd.read_csv(glob.glob(\"./InData/RoBERTa-LM/Final\"+str(tag)+\"*.csv\")[0], sep=\",\")\n",
    "\n",
    "############# FT RoBERTa ##############\n",
    "\n",
    "df_edin_bt_05 = pd.read_csv(glob.glob(\"./Edin/BERTweet-05-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_1 = pd.read_csv(glob.glob(\"./Edin/BERTweet-1-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_5 = pd.read_csv(glob.glob(\"./Edin/BERTweet-5-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_10 = pd.read_csv(glob.glob(\"./Edin/BERTweet-10-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_25 = pd.read_csv(glob.glob(\"./Edin/BERTweet-25-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_50 = pd.read_csv(glob.glob(\"./Edin/BERTweet-50-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_250 = pd.read_csv(glob.glob(\"./Edin/BERTweet-250-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_500 = pd.read_csv(glob.glob(\"./Edin/BERTweet-500-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bt_1500 = pd.read_csv(glob.glob(\"./Edin/BERTweet-1500-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bt_6600 = pd.read_csv(glob.glob(\"./Edin/BERTweet-6600-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "\n",
    "df_edin_bert_05 = pd.read_csv(glob.glob(\"./Edin/BERT-05-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_1 = pd.read_csv(glob.glob(\"./Edin/BERT-1-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_5 = pd.read_csv(glob.glob(\"./Edin/BERT-5-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_10 = pd.read_csv(glob.glob(\"./Edin/BERT-10-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_25 = pd.read_csv(glob.glob(\"./Edin/BERT-25-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_50 = pd.read_csv(glob.glob(\"./Edin/BERT-50-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_250 = pd.read_csv(glob.glob(\"./Edin/BERT-250-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bert_500 = pd.read_csv(glob.glob(\"./Edin/BERT-500-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_bert_1500 = pd.read_csv(glob.glob(\"./Edin/BERT-1500-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_bert_6600 = pd.read_csv(glob.glob(\"./Edin/BERT-6600-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "\n",
    "df_edin_rob_05 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-05-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_1 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-1-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_5 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-5-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_10 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-10-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_25 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-25-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_50 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-50-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_250 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-250-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_rob_500 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-500-LM/Final\"+str(tag)+\"*_.csv\")[0],sep=\",\")\n",
    "df_edin_rob_1500 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-1500-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")\n",
    "df_edin_rob_6600 = pd.read_csv(glob.glob(\"./Edin/RoBERTa-6600-LM/Final\"+str(tag)+\"*_.csv\")[0], sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_edin_bert_1['Data_Set']=df_edin_bert_1[\"Data_Set\"].apply(deParaDatasetName)\n",
    "#df_edin_bert_1['Data_Set'] = df_edin_bert_1['Data_Set'].map(str)\n",
    "#balance['Data_Set'] = balance['Data_Set'].map(str)\n",
    "#df_edin_bert_1_ = df_edin_bert_1.merge(balance,how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1595009919500,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "NCf2vK6MNjkR"
   },
   "outputs": [],
   "source": [
    "#frames = [dfstatic,df_btw_static,df_roberta,df_bert,df_bertweet,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_1500,df_edin_bt_6600,df_Indata_rb,df_Indata_br,df_Indata_bt,df_LOO_br,df_LOO_rb,df_LOO_bt,df_22dt_br,df_22dt_rb,df_22dt_bt]\n",
    "#frames = [df_bertweet,df_22dt_bt,df_22dt_br,df_22dt_rb,df_LOO_bt,df_LOO_br,df_LOO_rb,df_Indata_br,df_Indata_rb,df_Indata_bt,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_1500,df_edin_bt_6600]\n",
    "\n",
    "#Static\n",
    "#frames = [dfstatic, dfStatic,df_btw_static]\n",
    "\n",
    "#Context\n",
    "#frames = [dfStatic, df_roberta,df_bert,df_bertweet]\n",
    "\n",
    "#best context vs static\n",
    "#frames = [dfstatic, dfStatic,df_btw_static,df_roberta,df_bert,df_bertweet ]\n",
    "\n",
    "#roberta vs roberta tunado\n",
    "#frames = [df_roberta,df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,df_LOO_rb,df_Indata_rb,df_22dt_rb]\n",
    "\n",
    "#bert vs bert tunado\n",
    "#frames = [df_bert,df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,df_LOO_br,df_Indata_br,df_22dt_br]\n",
    "\n",
    "#bertweet vs bertweet tunado\n",
    "#frames = [df_bertweet,df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600,df_LOO_bt,df_Indata_bt,df_22dt_bt]\n",
    "\n",
    "#bertweet vs todos modelos\n",
    "#frames = [df_bertweet,df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600,df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600,df_Indata_rb,df_Indata_br,df_LOO_br,df_LOO_rb,df_22dt_br,df_22dt_rb]\n",
    "\n",
    "#Best indata, LOO, 22dataset\n",
    "#frames = [df_Indata_rb,df_Indata_br,df_Indata_bt,df_LOO_br,df_LOO_bt,df_LOO_rb,df_22dt_br,df_22dt_rb,df_22dt_bt]\n",
    "#frames = [df_Indata_bt,df_LOO_bt,df_22dt_bt]\n",
    "\n",
    "#BEST OVER ALL FINE TUNING sem sentimento\n",
    "'''frames = [df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600, \\\n",
    "          df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600, \\\n",
    "          df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600]\n",
    "'''\n",
    "\n",
    "#BEST OVER ALL FINE TUNING\n",
    "'''frames = [df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600, \\\n",
    "          df_LOO_bt,df_Indata_bt,df_22dt_bt, \\\n",
    "          df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600, \\\n",
    "          df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600, \\\n",
    "          df_Indata_rb,df_Indata_br,df_LOO_br,df_LOO_rb,df_22dt_br,df_22dt_rb]'''\n",
    "\n",
    "#BEST OVER ALL MODELS\n",
    "frames = [dfStatic,df_roberta,df_bert,df_bertweet, \\\n",
    "          df_edin_bt_05,df_edin_bt_1,df_edin_bt_5,df_edin_bt_10,df_edin_bt_25,df_edin_bt_50,df_edin_bt_250,df_edin_bt_500,df_edin_bt_1500,df_edin_bt_6600, \\\n",
    "          df_LOO_bt,df_Indata_bt,df_22dt_bt, \\\n",
    "          df_edin_rob_05,df_edin_rob_1,df_edin_rob_5,df_edin_rob_10,df_edin_rob_25,df_edin_rob_50,df_edin_rob_250,df_edin_rob_500,df_edin_rob_1500,df_edin_rob_6600, \\\n",
    "          df_edin_bert_05,df_edin_bert_1,df_edin_bert_5,df_edin_bert_10,df_edin_bert_25,df_edin_bert_50,df_edin_bert_250,df_edin_bert_500,df_edin_bert_1500,df_edin_bert_6600, \\\n",
    "          df_Indata_rb,df_Indata_br,df_LOO_br,df_LOO_rb,df_22dt_br,df_22dt_rb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1595009919501,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "IwrQ3coXNuIe"
   },
   "outputs": [],
   "source": [
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1595009919502,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "SkBoFHgNwndl"
   },
   "outputs": [],
   "source": [
    "result[[\"accuracy\", \"f1_macro\"]] = result[[\"accuracy\", \"f1_macro\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1595009919504,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "05WFV64O2zJN"
   },
   "outputs": [],
   "source": [
    "result[\"Data_Set\"] = result[\"Data_Set\"].apply(deParaDatasetName)\n",
    "result[\"Embedding\"] = result[\"Embedding\"].apply(deParaEmbeddingName)\n",
    "result[\"Classifier_Model\"] = result[\"Classifier_Model\"].apply(deParaClassifierName)\n",
    "result['Emb+Class'] = result[\"Embedding\"] + \"-\"+result[\"Classifier_Model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1595009919508,
     "user": {
      "displayName": "Ricardo Moura",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh4BPVXR6IythXBJgaEEl5JosseAHCEwlRIxpBjww=s64",
      "userId": "10784804889662280666"
     },
     "user_tz": 180
    },
    "id": "n2i9Vw-ahUnG"
   },
   "outputs": [],
   "source": [
    "result_acc = result.sort_values(by=['Data_Set', 'accuracy'], ascending=False)\n",
    "result_f1 = result.sort_values(by=['Data_Set', 'f1_macro'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_acc[\"rank\"] = result_acc.groupby(\"Data_Set\")[\"accuracy\"].rank(\"average\", ascending=False)\n",
    "result_f1[\"rank\"] = result_f1.groupby(\"Data_Set\")[\"f1_macro\"].rank(\"average\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Data_Set</th>\n",
       "      <th>Emb+Class</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>93.04</td>\n",
       "      <td>93.02</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet-5K</td>\n",
       "      <td>stm</td>\n",
       "      <td>BERTweet-5K-SVM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>93.02</td>\n",
       "      <td>92.99</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet-500K</td>\n",
       "      <td>stm</td>\n",
       "      <td>BERTweet-500K-SVM</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.73</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet\\_LOO</td>\n",
       "      <td>stm</td>\n",
       "      <td>BERTweet\\_LOO-SVM</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>92.70</td>\n",
       "      <td>92.60</td>\n",
       "      <td>SVM</td>\n",
       "      <td>BERTweet\\_22Dt</td>\n",
       "      <td>stm</td>\n",
       "      <td>BERTweet\\_22Dt-SVM</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>92.47</td>\n",
       "      <td>92.45</td>\n",
       "      <td>LR</td>\n",
       "      <td>BERTweet\\_LOO</td>\n",
       "      <td>stm</td>\n",
       "      <td>BERTweet\\_LOO-LR</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>67.29</td>\n",
       "      <td>62.99</td>\n",
       "      <td>SVM</td>\n",
       "      <td>SSWE</td>\n",
       "      <td>HCR</td>\n",
       "      <td>SSWE-SVM</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>66.77</td>\n",
       "      <td>64.45</td>\n",
       "      <td>LR</td>\n",
       "      <td>w2v-Edin</td>\n",
       "      <td>HCR</td>\n",
       "      <td>w2v-Edin-LR</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>65.77</td>\n",
       "      <td>63.03</td>\n",
       "      <td>LR</td>\n",
       "      <td>Bertweet: vinai/bertweet-base / STATIC_AVG</td>\n",
       "      <td>HCR</td>\n",
       "      <td>Bertweet: vinai/bertweet-base / STATIC_AVG-LR</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>65.20</td>\n",
       "      <td>62.42</td>\n",
       "      <td>LR</td>\n",
       "      <td>BERT-static</td>\n",
       "      <td>HCR</td>\n",
       "      <td>BERT-static-LR</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>65.09</td>\n",
       "      <td>61.89</td>\n",
       "      <td>LR</td>\n",
       "      <td>SSWE</td>\n",
       "      <td>HCR</td>\n",
       "      <td>SSWE-LR</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  f1_macro Classifier_Model  \\\n",
       "87      93.04     93.02              SVM   \n",
       "87      93.02     92.99              SVM   \n",
       "87      92.75     92.73              SVM   \n",
       "87      92.70     92.60              SVM   \n",
       "21      92.47     92.45               LR   \n",
       "..        ...       ...              ...   \n",
       "377     67.29     62.99              SVM   \n",
       "350     66.77     64.45               LR   \n",
       "415     65.77     63.03               LR   \n",
       "410     65.20     62.42               LR   \n",
       "375     65.09     61.89               LR   \n",
       "\n",
       "                                      Embedding Data_Set  \\\n",
       "87                                  BERTweet-5K      stm   \n",
       "87                                BERTweet-500K      stm   \n",
       "87                                BERTweet\\_LOO      stm   \n",
       "87                               BERTweet\\_22Dt      stm   \n",
       "21                                BERTweet\\_LOO      stm   \n",
       "..                                          ...      ...   \n",
       "377                                        SSWE      HCR   \n",
       "350                                    w2v-Edin      HCR   \n",
       "415  Bertweet: vinai/bertweet-base / STATIC_AVG      HCR   \n",
       "410                                 BERT-static      HCR   \n",
       "375                                        SSWE      HCR   \n",
       "\n",
       "                                         Emb+Class   rank  \n",
       "87                                 BERTweet-5K-SVM    1.0  \n",
       "87                               BERTweet-500K-SVM    2.0  \n",
       "87                               BERTweet\\_LOO-SVM    3.0  \n",
       "87                              BERTweet\\_22Dt-SVM    4.0  \n",
       "21                                BERTweet\\_LOO-LR    5.0  \n",
       "..                                             ...    ...  \n",
       "377                                       SSWE-SVM  276.0  \n",
       "350                                    w2v-Edin-LR  277.0  \n",
       "415  Bertweet: vinai/bertweet-base / STATIC_AVG-LR  278.0  \n",
       "410                                 BERT-static-LR  279.0  \n",
       "375                                        SSWE-LR  280.0  \n",
       "\n",
       "[6160 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pivot_acc = pd.pivot_table(result_acc, values='rank', index=['Data_Set'],columns=['Embedding'], aggfunc=np.sum)\n",
    "#pivot_af1 = pd.pivot_table(result_f1, values='rank', index=['Data_Set'],columns=['Embedding'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet\\_LOO&LR&17.3&BERTweet\\_LOO&LR&15.52\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_22Dt&LR&18.16&BERTweet\\_22Dt&LR&16.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_LOO&MLP&18.55&BERTweet-5K&LR&18.64\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_22Dt&MLP&19.36&BERTweet\\_22Dt&MLP&20.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-5K&LR&20.64&BERTweet\\_LOO&MLP&21.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-5K&MLP&23.14&BERTweet-25K&SVM&22.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-25K&MLP&24.3&BERTweet-10K&SVM&23.16\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-25K&LR&26.23&BERTweet-25K&LR&23.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1K&MLP&26.91&BERTweet-10K&LR&23.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-50K&MLP&27.02&BERTweet\\_22Dt&SVM&24.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_22Dt&SVM&28.3&BERTweet-1K&LR&25.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-25K&SVM&28.34&BERTweet\\_LOO&SVM&25.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-10K&LR&28.61&BERTweet-5K&MLP&26.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1K&LR&29.7&BERTweet-25K&MLP&26.14\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-10K&SVM&29.86&BERTweet-50K&LR&27.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-10K&MLP&30.27&BERTweet-50K&MLP&28.34\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_LOO&SVM&31.0&BERTweet-1K&MLP&28.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-50K&LR&32.07&BERTweet-50K&SVM&28.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-50K&SVM&34.57&BERTweet-250K&LR&31.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_InData&LR&35.91&BERTweet\\_InData&LR&32.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-250K&LR&35.98&BERTweet-10K&MLP&32.73\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-250K&MLP&38.61&BERTweet-5K&SVM&33.45\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-5K&SVM&40.8&BERTweet-250K&SVM&34.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-250K&SVM&41.11&BERTweet-1K&SVM&37.25\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_InData&MLP&41.66&BERTweet-250K&MLP&39.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-05K&LR&44.93&BERTweet-05K&LR&39.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1K&SVM&47.5&BERTweet-500K&SVM&40.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_22Dt&MLP&48.59&BERTweet\\_InData&MLP&43.14\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-500K&SVM&48.95&RoBERTa\\_22Dt&LR&45.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_22Dt&LR&49.95&BERTweet&LR&46.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet&LR&50.09&BERTweet-500K&LR&48.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-500K&MLP&50.14&RoBERTa\\_LOO&LR&50.11\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-05K&MLP&50.82&RoBERTa\\_22Dt&MLP&50.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet&MLP&51.64&BERT\\_InData&LR&51.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_LOO&MLP&54.52&BERTweet-05K&MLP&52.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_InData&LR&57.0&BERTweet&MLP&52.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_LOO&LR&57.39&BERTweet-500K&MLP&52.34\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-500K&LR&57.41&BERTweet\\_InData&SVM&54.36\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_InData&MLP&58.02&BERTweet-1500K&SVM&55.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-50K&MLP&59.2&BERTweet-1500K&LR&55.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1500K&MLP&61.86&RoBERTa\\_LOO&MLP&56.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-500K&MLP&62.75&BERTweet-05K&SVM&58.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-6600K&MLP&64.18&BERTweet-6600K&LR&58.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-50K&LR&64.89&RoBERTa-50K&LR&58.91\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1500K&LR&65.55&BERT\\_InData&MLP&59.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_22Dt&Xgb&65.64&BERTweet&SVM&61.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1500K&MLP&66.41&RoBERTa\\_InData&LR&61.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-05K&SVM&66.64&RoBERTa-50K&MLP&61.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_InData&LR&66.66&RoBERTa-5K&LR&62.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1500K&SVM&66.75&RoBERTa-1500K&MLP&63.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_InData&SVM&67.7&BERTweet-6600K&MLP&63.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-5K&LR&67.75&RoBERTa-1500K&LR&65.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-6600K&LR&68.86&RoBERTa-25K&LR&66.45\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_InData&MLP&69.2&BERTweet-6600K&SVM&66.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-25K&MLP&70.84&BERTweet-1500K&MLP&66.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-5K&MLP&70.93&RoBERTa-500K&LR&66.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_LOO&Xgb&72.5&RoBERTa-500K&MLP&67.09\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-25K&LR&72.57&RoBERTa-1K&LR&69.73\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1500K&LR&72.75&BERT\\_InData&SVM&71.11\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-10K&MLP&73.64&RoBERTa-250K&LR&71.64\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-500K&LR&74.09&RoBERTa\\_InData&MLP&71.84\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-5K&Xgb&74.16&RoBERTa-10K&LR&72.39\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet&SVM&75.73&RoBERTa-5K&MLP&73.16\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-250K&LR&76.89&RoBERTa-25K&MLP&75.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1K&Xgb&77.02&RoBERTa-10K&MLP&75.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-6600K&SVM&78.05&RoBERTa-05K&LR&76.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-10K&LR&78.86&RoBERTa-250K&MLP&81.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-250K&MLP&80.91&BERTweet\\_22Dt&Xgb&82.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1K&LR&81.43&RoBERTa-1K&MLP&83.66\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1K&MLP&82.55&BERTweet\\_LOO&Xgb&84.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_InData&SVM&85.5&BERT\\_LOO&SVM&87.34\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-05K&LR&85.82&BERT\\_22Dt&SVM&88.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-10K&Xgb&87.16&BERTweet-5K&Xgb&88.61\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_22Dt&MLP&88.05&BERT\\_22Dt&MLP&89.66\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_22Dt&Xgb&90.68&BERT-6600K&LR&91.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-05K&MLP&91.27&RoBERTa-05K&MLP&91.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_LOO&MLP&92.45&RoBERTa&LR&94.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_LOO&Xgb&94.86&BERTweet-1K&Xgb&94.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa&MLP&96.57&RoBERTa-6600K&LR&95.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-25K&Xgb&98.98&BERT\\_LOO&MLP&95.36\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-6600K&LR&99.32&BERT-250K&SVM&96.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-6600K&MLP&99.66&RoBERTa&MLP&98.39\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_InData&Xgb&100.02&BERT-5K&SVM&99.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1500K&MLP&100.55&BERT-1500K&MLP&100.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-50K&Xgb&100.61&BERT-50K&SVM&100.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-500K&Xgb&101.16&BERT-1500K&LR&101.84\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_22Dt&SVM&101.32&BERT&SVM&101.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-6600K&MLP&102.27&BERTweet-10K&Xgb&102.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa&LR&102.98&BERT-6600K&MLP&102.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-500K&MLP&103.0&BERT\\_22Dt&LR&103.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_LOO&SVM&103.66&RoBERTa-6600K&MLP&104.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-250K&MLP&103.73&BERT-250K&MLP&104.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-6600K&LR&107.43&BERT-500K&MLP&104.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-250K&Xgb&108.5&BERT-05K&SVM&104.8\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT&MLP&109.36&RoBERTa\\_LOO&Xgb&105.02\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-50K&MLP&110.59&BERT-500K&SVM&105.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1500K&LR&111.41&RoBERTa\\_22Dt&Xgb&105.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_22Dt&LR&111.7&BERT-1500K&SVM&106.45\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-05K&Xgb&112.2&BERT-1K&SVM&106.95\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-5K&SVM&112.52&BERT-10K&SVM&107.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-250K&SVM&113.23&BERT-25K&SVM&107.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-5K&MLP&113.68&BERT-500K&LR&108.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-05K&MLP&114.39&BERT&MLP&112.02\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-500K&LR&116.82&BERT-50K&MLP&112.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-50K&SVM&117.5&BERTweet-25K&Xgb&113.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-250K&Xgb&118.68&BERT\\_LOO&LR&115.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT&SVM&118.82&BERTweet-50K&Xgb&116.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1K&MLP&119.52&BERT-05K&MLP&117.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-25K&Xgb&119.98&BERTweet\\_InData&Xgb&117.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-10K&Xgb&120.11&RoBERTa-1500K&SVM&117.43\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_InData&Xgb&120.11&BERT-5K&MLP&117.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-50K&Xgb&120.95&RoBERTa\\_22Dt&SVM&119.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-05K&SVM&120.98&BERT-250K&LR&119.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_InData&Xgb&121.0&BERTweet-500K&Xgb&120.14\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-10K&MLP&121.36&BERT&LR&121.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1K&SVM&122.0&BERT-1K&MLP&122.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_LOO&LR&122.3&BERTweet-250K&Xgb&123.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-25K&MLP&123.11&BERT-10K&MLP&124.02\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-10K&SVM&124.73&RoBERTa-500K&SVM&124.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-25K&SVM&125.36&BERT-05K&LR&125.09\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-500K&Xgb&126.05&BERT-6600K&SVM&125.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-5K&Xgb&126.09&BERT-25K&MLP&125.95\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT&LR&126.55&BERT-5K&LR&125.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-500K&SVM&128.98&RoBERTa\\_LOO&SVM&127.89\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1K&Xgb&129.09&BERTweet-05K&Xgb&129.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet&Xgb&129.23&BERT-50K&LR&130.89\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-250K&LR&130.09&BERT-1K&LR&132.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-5K&LR&130.34&BERT-25K&LR&132.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1500K&SVM&130.93&RoBERTa-250K&Xgb&133.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-05K&LR&132.32&RoBERTa\\_InData&Xgb&133.64\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1500K&Xgb&133.36&RoBERTa-50K&Xgb&133.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1500K&Xgb&134.36&RoBERTa-6600K&SVM&135.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1K&LR&135.84&RoBERTa-250K&SVM&135.43\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_22Dt&RF&137.7&RoBERTa-10K&Xgb&135.91\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-50K&LR&138.84&RoBERTa-50K&SVM&137.14\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-25K&LR&139.09&BERT\\_InData&Xgb&138.09\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_22Dt&SVM&140.05&BERT-10K&LR&138.61\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1500K&SVM&141.11&RoBERTa-25K&Xgb&139.43\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_LOO&Xgb&141.55&RoBERTa\\_InData&SVM&140.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_LOO&RF&143.25&RoBERTa-5K&SVM&140.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-5K&RF&144.07&RoBERTa-5K&Xgb&141.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-6600K&Xgb&144.77&BERTweet&Xgb&142.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_22Dt&Xgb&145.39&RoBERTa-static&SVM&143.73\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-500K&SVM&146.39&RoBERTa-500K&Xgb&143.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-6600K&Xgb&146.73&RoBERTa-1K&Xgb&146.07\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-10K&LR&147.57&BERTweet-1500K&Xgb&146.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-25K&RF&149.07&RoBERTa-10K&SVM&148.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-05K&Xgb&149.64&RoBERTa-1500K&Xgb&149.07\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_LOO&SVM&150.0&w2v-Edin&SVM&151.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-10K&RF&151.64&RoBERTa-25K&SVM&152.89\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-6600K&SVM&152.23&RoBERTa-1K&SVM&155.36\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-250K&Xgb&152.82&RoBERTa-6600K&Xgb&156.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-static&SVM&153.41&BERT\\_LOO&Xgb&158.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa&Xgb&153.5&BERT\\_22Dt&Xgb&158.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_22Dt&RF&153.5&BERTweet\\_22Dt&RF&159.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-05K&Xgb&155.7&BERTweet-6600K&Xgb&159.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_LOO&RF&155.89&RoBERTa-05K&Xgb&163.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1500K&Xgb&155.89&BERTweet-5K&RF&164.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_InData&SVM&156.59&RoBERTa-05K&SVM&164.84\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1K&Xgb&156.68&RoBERTa&Xgb&165.25\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-250K&SVM&158.34&Emo2Vec&SVM&165.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-50K&Xgb&158.95&BERTweet\\_LOO&RF&165.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-500K&Xgb&160.89&BERT-static&SVM&166.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-6600K&SVM&161.05&BERT-250K&Xgb&167.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-50K&SVM&161.66&RoBERTa-static&MLP&167.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1K&RF&161.82&BERT-05K&Xgb&168.64\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-5K&SVM&162.68&BERT-1500K&Xgb&169.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-5K&Xgb&162.77&BERT-500K&Xgb&169.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-25K&Xgb&162.98&w2v-Edin&MLP&170.09\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-10K&Xgb&163.61&BERTweet-25K&RF&170.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-6600K&Xgb&164.86&BERT-50K&Xgb&170.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-250K&RF&166.43&BERT-1K&Xgb&171.39\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-50K&RF&167.27&BERT-6600K&Xgb&171.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-static&MLP&168.98&Emo2Vec&LR&171.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-10K&SVM&169.89&w2v-GN&SVM&172.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Edin&SVM&171.89&RoBERTa\\_22Dt&RF&172.7\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-500K&RF&172.84&RoBERTa-static&LR&172.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_InData&RF&173.73&RoBERTa\\_LOO&RF&173.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-25K&SVM&174.2&BERTweet-10K&RF&173.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Edin&MLP&174.91&BERT-10K&Xgb&175.11\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1K&SVM&177.43&BERT-25K&Xgb&175.61\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-250K&RF&178.05&BERT-5K&Xgb&175.61\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT&Xgb&180.45&DeepMoji&SVM&178.36\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-500K&RF&180.82&GloVe-TWT&LR&178.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-50K&RF&181.68&BERT-static&MLP&178.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Emo2Vec&Xgb&182.77&RoBERTa&SVM&179.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1500K&RF&182.86&EWE&LR&180.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-GN&SVM&182.95&BERTweet-1K&RF&180.95\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_InData&RF&183.05&w2v-GN&MLP&182.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-static&MLP&183.32&Emo2Vec&Xgb&184.11\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-static&SVM&185.07&w2v-GN&LR&185.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-05K&SVM&186.41&GloVe-TWT&MLP&185.8\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-05K&RF&187.11&BERTweet-50K&RF&186.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-5K&RF&187.7&BERTweet-250K&RF&186.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_LOO&RF&188.43&GloVe-WP&LR&188.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_22Dt&RF&188.68&SSWE&LR&188.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Emo2Vec&SVM&189.27&BERT&Xgb&188.89\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_InData&RF&189.36&fastText&MLP&189.09\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-GN&MLP&189.77&EWE&MLP&189.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-25K&RF&190.09&SSWE&SVM&191.45\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-TWT&MLP&191.43&BERTweet\\_InData&RF&192.36\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Emo2Vec&RF&191.61&BERTweet-500K&RF&193.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "fastText&MLP&194.41&Bertweet: vinai/bertweet-base / STATIC_AVG&MLP&193.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1500K&RF&195.32&DeepMoji&MLP&193.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Emo2Vec&LR&196.09&fastText&SVM&194.82\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-10K&RF&196.11&RoBERTa-250K&RF&195.64\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa&SVM&196.32&GloVe-WP&SVM&195.95\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "EWE&MLP&196.89&EWE&SVM&196.34\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-static&LR&199.05&w2v-Araque&SVM&196.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "SSWE&RF&199.5&Emo2Vec&MLP&198.52\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Bertweet: vinai/bertweet-base / STATIC_AVG&MLP&199.93&DeepMoji&LR&198.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "DeepMoji&SVM&200.3&GloVe-WP&MLP&198.89\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet&RF&200.61&RoBERTa\\_InData&RF&199.39\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-250K&RF&201.27&RoBERTa-500K&RF&199.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "DeepMoji&MLP&202.07&RoBERTa-50K&RF&199.95\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Edin&Xgb&202.77&RoBERTa-1500K&RF&202.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "TF-IDF&SVM&203.07&SSWE&Xgb&203.23\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-50K&RF&203.18&SSWE&MLP&203.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-500K&RF&203.18&Emo2Vec&RF&204.43\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-TWT&LR&204.61&BERTweet-05K&RF&204.89\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-6600K&RF&205.07&TF-IDF&LR&205.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Emo2Vec&MLP&205.45&w2v-Araque&MLP&206.07\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-5K&RF&206.02&BERT\\_InData&RF&206.61\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "SSWE&Xgb&206.77&BERT\\_LOO&RF&206.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1K&RF&207.09&BERT\\_22Dt&RF&207.11\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-TWT&Xgb&207.84&RoBERTa-5K&RF&207.27\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1500K&RF&208.11&GloVe-TWT&SVM&207.57\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "EWE&LR&208.61&w2v-Edin&Xgb&207.7\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1K&RF&208.84&RoBERTa-25K&RF&209.36\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-25K&RF&209.02&SSWE&RF&209.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-WP&MLP&209.07&BERTweet-1500K&RF&212.52\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-05K&RF&209.23&fastText&LR&212.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-6600K&RF&209.32&GloVe-TWT&Xgb&212.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-10K&RF&209.59&RoBERTa-10K&RF&213.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-GN&LR&209.82&w2v-Araque&LR&213.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "SSWE&LR&211.75&Bertweet: vinai/bertweet-base / STATIC_AVG&SVM&214.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "DeepMoji&Xgb&211.93&TF-IDF&SVM&215.52\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "SSWE&MLP&212.27&DeepMoji&Xgb&216.8\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Araque&SVM&212.66&BERTweet&RF&217.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-05K&RF&213.32&w2v-Edin&LR&217.64\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-WP&LR&214.66&BERT-250K&RF&218.7\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "EWE&Xgb&214.7&EWE&Xgb&219.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa&RF&215.02&w2v-GN&Xgb&220.14\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Araque&MLP&215.11&BERT-500K&RF&220.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-GN&Xgb&215.16&BERT-50K&RF&220.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "TF-IDF&LR&215.2&BERTweet-6600K&RF&221.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-6600K&RF&216.27&BERT-5K&RF&223.25\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "SSWE&SVM&218.14&RoBERTa-1K&RF&223.43\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "EWE&SVM&219.89&BERT-1500K&RF&224.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-WP&SVM&222.55&BERT-6600K&RF&225.34\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "fastText&SVM&222.8&TF-IDF&MLP&225.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT&RF&222.93&RoBERTa-05K&RF&226.11\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "fastText&Xgb&224.36&BERT-1K&RF&226.18\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-static&Xgb&225.18&fastText&Xgb&226.84\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "TF-IDF&MLP&225.5&BERT-25K&RF&227.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "TF-IDF&RF&226.52&BERT-10K&RF&227.64\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "DeepMoji&LR&227.61&BERT-05K&RF&230.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-WP&Xgb&229.75&RoBERTa-6600K&RF&230.89\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Edin&RF&231.89&GloVe-WP&Xgb&231.0\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "TF-IDF&Xgb&233.84&RoBERTa&RF&232.7\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-static&Xgb&234.0&RoBERTa-static&Xgb&233.7\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-TWT&SVM&236.39&TF-IDF&Xgb&237.39\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Bertweet: vinai/bertweet-base / STATIC_AVG&SVM&236.95&TF-IDF&RF&237.52\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Araque&Xgb&237.0&BERT-static&LR&238.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-TWT&RF&237.82&w2v-Araque&Xgb&238.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Araque&LR&238.27&BERT&RF&238.61\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "fastText&LR&241.7&BERT-static&Xgb&240.41\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "DeepMoji&RF&243.75&w2v-Edin&RF&244.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Bertweet: vinai/bertweet-base / STATIC_AVG&Xgb&243.84&Bertweet: vinai/bertweet-base / STATIC_AVG&Xgb&247.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Edin&LR&244.95&GloVe-TWT&RF&251.52\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "EWE&RF&247.23&DeepMoji&RF&252.86\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Araque&RF&249.75&Bertweet: vinai/bertweet-base / STATIC_AVG&LR&253.14\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-GN&RF&250.0&EWE&RF&256.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-WP&RF&253.68&w2v-Araque&RF&259.8\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "fastText&RF&255.75&w2v-GN&RF&261.7\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-static&RF&257.32&GloVe-WP&RF&263.11\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-static&RF&259.7&fastText&RF&266.95\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-static&LR&263.34&BERT-static&RF&267.75\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Bertweet: vinai/bertweet-base / STATIC_AVG&RF&265.91&RoBERTa-static&RF&269.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Bertweet: vinai/bertweet-base / STATIC_AVG&LR&274.43&Bertweet: vinai/bertweet-base / STATIC_AVG&RF&275.43\\\\\n"
     ]
    }
   ],
   "source": [
    "acc = result_acc.groupby(by=[\"Embedding\",\"Classifier_Model\"]).sum()['rank'].sort_values().reset_index()\n",
    "f1 = result_f1.groupby(by=[\"Embedding\",\"Classifier_Model\"]).sum()['rank'].sort_values().reset_index()\n",
    "monta_tabela_latex_top_rank_sum(acc,f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Classifier_Model</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERTweet\\_LOO</td>\n",
       "      <td>LR</td>\n",
       "      <td>380.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERTweet\\_22Dt</td>\n",
       "      <td>LR</td>\n",
       "      <td>399.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BERTweet\\_LOO</td>\n",
       "      <td>MLP</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERTweet\\_22Dt</td>\n",
       "      <td>MLP</td>\n",
       "      <td>426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BERTweet-5K</td>\n",
       "      <td>LR</td>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>BERT-static</td>\n",
       "      <td>RF</td>\n",
       "      <td>5661.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>RoBERTa-static</td>\n",
       "      <td>RF</td>\n",
       "      <td>5713.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>BERT-static</td>\n",
       "      <td>LR</td>\n",
       "      <td>5793.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Bertweet: vinai/bertweet-base / STATIC_AVG</td>\n",
       "      <td>RF</td>\n",
       "      <td>5850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Bertweet: vinai/bertweet-base / STATIC_AVG</td>\n",
       "      <td>LR</td>\n",
       "      <td>6037.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Embedding Classifier_Model    rank\n",
       "0                                 BERTweet\\_LOO               LR   380.5\n",
       "1                                BERTweet\\_22Dt               LR   399.5\n",
       "2                                 BERTweet\\_LOO              MLP   408.0\n",
       "3                                BERTweet\\_22Dt              MLP   426.0\n",
       "4                                   BERTweet-5K               LR   454.0\n",
       "..                                          ...              ...     ...\n",
       "275                                 BERT-static               RF  5661.0\n",
       "276                              RoBERTa-static               RF  5713.5\n",
       "277                                 BERT-static               LR  5793.5\n",
       "278  Bertweet: vinai/bertweet-base / STATIC_AVG               RF  5850.0\n",
       "279  Bertweet: vinai/bertweet-base / STATIC_AVG               LR  6037.5\n",
       "\n",
       "[280 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      22\n",
       "1      22\n",
       "2      22\n",
       "3      22\n",
       "4      22\n",
       "       ..\n",
       "275    22\n",
       "276    22\n",
       "277    22\n",
       "278    22\n",
       "279    22\n",
       "Name: rank, Length: 280, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_acc.groupby(by=[\"Embedding\",\"Classifier_Model\"]).count().reset_index()['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       17.295455\n",
       "1       18.159091\n",
       "2       18.545455\n",
       "3       19.363636\n",
       "4       20.636364\n",
       "          ...    \n",
       "275    257.318182\n",
       "276    259.704545\n",
       "277    263.340909\n",
       "278    265.909091\n",
       "279    274.431818\n",
       "Name: rank, Length: 280, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc['rank']/result_acc.groupby(by=[\"Embedding\",\"Classifier_Model\"]).count().reset_index()['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP&103.3&MLP&103.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "LR&115.0&LR&103.97\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "SVM&133.58&SVM&116.87\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Xgb&150.17&Xgb&161.67\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RF&200.45&RF&216.79\\\\\n"
     ]
    }
   ],
   "source": [
    "acc = result_acc.groupby(by=[\"Classifier_Model\"]).sum()['rank'].sort_values().reset_index()\n",
    "f1 = result_f1.groupby(by=[\"Classifier_Model\"]).sum()['rank'].sort_values().reset_index()\n",
    "monta_tabela_latex_top_rank_sum_class(acc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1232\n",
       "1    1232\n",
       "2    1232\n",
       "3    1232\n",
       "4    1232\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_acc.groupby(by=[\"Classifier_Model\"]).count().reset_index()['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    103.298295\n",
       "1    115.003247\n",
       "2    133.579951\n",
       "3    150.172078\n",
       "4    200.446429\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc['rank']/result_acc.groupby(by=[\"Classifier_Model\"]).count().reset_index()['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTweet\\_22Dt&53.83&BERTweet\\_22Dt&60.67\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_LOO&56.52&BERTweet\\_LOO&62.59\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-5K&60.56&BERTweet-5K&66.21\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-25K&65.38&BERTweet-25K&71.07\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-10K&65.51&BERTweet-10K&71.17\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1K&68.59&BERTweet-1K&73.32\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-50K&72.31&BERTweet-50K&77.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-250K&78.13&BERTweet-250K&82.9\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet\\_InData&83.8&BERTweet\\_InData&87.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-500K&86.1&BERTweet-500K&90.85\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-05K&92.34&BERTweet-05K&96.77\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_22Dt&96.55&RoBERTa\\_22Dt&98.72\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet&101.46&RoBERTa\\_LOO&102.68\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_InData&102.0&BERTweet&103.92\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_LOO&102.53&BERT\\_InData&105.38\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-1500K&105.68&BERTweet-1500K&107.33\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERTweet-6600K&112.58&BERTweet-6600K&113.93\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-50K&117.68&RoBERTa-50K&118.34\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-500K&118.02&RoBERTa-1500K&119.48\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1500K&118.39&RoBERTa-500K&120.36\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa\\_InData&119.3&RoBERTa\\_InData&121.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-250K&122.57&RoBERTa-250K&123.65\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-5K&123.03&RoBERTa-5K&124.88\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-25K&125.54&RoBERTa-25K&128.67\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_22Dt&127.03&RoBERTa-10K&129.15\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-10K&127.72&BERT\\_22Dt&129.5\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT\\_LOO&129.68&BERT\\_LOO&132.76\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-1K&135.52&RoBERTa-1K&135.65\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-250K&140.23&BERT-1500K&140.55\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1500K&141.38&BERT-250K&141.29\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-500K&142.57&BERT-500K&141.78\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-05K&144.47&BERT-6600K&143.25\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-5K&145.07&RoBERTa-6600K&144.54\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-6600K&145.08&RoBERTa-05K&144.54\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-50K&145.81&BERT-50K&146.95\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-6600K&146.36&BERT-5K&148.4\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-05K&147.34&BERT-05K&149.2\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-1K&148.58&BERT-1K&151.8\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT&151.62&BERT&152.54\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-25K&151.91&BERT-25K&153.81\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa&152.88&RoBERTa&153.98\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-10K&153.37&BERT-10K&154.49\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Emo2Vec&193.04&Emo2Vec&184.92\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "RoBERTa-static&201.26&RoBERTa-static&197.49\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Edin&205.28&w2v-Edin&198.3\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-GN&209.54&SSWE&199.29\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "SSWE&209.69&w2v-GN&204.38\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-TWT&215.62&GloVe-TWT&207.22\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "DeepMoji&217.13&DeepMoji&208.08\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "EWE&217.46&EWE&208.43\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "TF-IDF&220.83&GloVe-WP&215.45\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "BERT-static&224.61&fastText&218.05\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "GloVe-WP&225.94&BERT-static&218.4\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "fastText&227.8&w2v-Araque&222.85\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "w2v-Araque&230.56&TF-IDF&224.34\\\\\n",
      "\\rule{0pt}{3.0ex}\n",
      "Bertweet: vinai/bertweet-base / STATIC_AVG&244.21&Bertweet: vinai/bertweet-base / STATIC_AVG&237.01\\\\\n"
     ]
    }
   ],
   "source": [
    "acc = result_acc.groupby(by=[\"Embedding\"]).sum()['rank'].sort_values().reset_index()\n",
    "f1 = result_f1.groupby(by=[\"Embedding\"]).sum()['rank'].sort_values().reset_index()\n",
    "monta_tabela_latex_top_rank_sum_emb(acc,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      53.831818\n",
       "1      56.518182\n",
       "2      60.559091\n",
       "3      65.381818\n",
       "4      65.509091\n",
       "5      68.590909\n",
       "6      72.309091\n",
       "7      78.127273\n",
       "8      83.804545\n",
       "9      86.100000\n",
       "10     92.340909\n",
       "11     96.554545\n",
       "12    101.459091\n",
       "13    102.000000\n",
       "14    102.531818\n",
       "15    105.677273\n",
       "16    112.577273\n",
       "17    117.677273\n",
       "18    118.018182\n",
       "19    118.390909\n",
       "20    119.300000\n",
       "21    122.572727\n",
       "22    123.031818\n",
       "23    125.536364\n",
       "24    127.027273\n",
       "25    127.722727\n",
       "26    129.677273\n",
       "27    135.518182\n",
       "28    140.227273\n",
       "29    141.377273\n",
       "30    142.572727\n",
       "31    144.472727\n",
       "32    145.068182\n",
       "33    145.077273\n",
       "34    145.813636\n",
       "35    146.359091\n",
       "36    147.340909\n",
       "37    148.577273\n",
       "38    151.622727\n",
       "39    151.913636\n",
       "40    152.877273\n",
       "41    153.372727\n",
       "42    193.040909\n",
       "43    201.263636\n",
       "44    205.281818\n",
       "45    209.540909\n",
       "46    209.686364\n",
       "47    215.618182\n",
       "48    217.131818\n",
       "49    217.463636\n",
       "50    220.827273\n",
       "51    224.609091\n",
       "52    225.940909\n",
       "53    227.804545\n",
       "54    230.559091\n",
       "55    244.213636\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc['rank']/result_acc.groupby(by=[\"Embedding\"]).count().reset_index()['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNu7AB0kwJRPr+r17jbMTv3",
   "collapsed_sections": [],
   "mount_file_id": "18YqNJ9EiloCFcgw03FIBpEvdUpPY5fCt",
   "name": "organize_result_bestoverall.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
